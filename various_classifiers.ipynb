{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from new_datasets_py import create_subsets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (balanced_accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, log_loss)\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          close_values  label\n",
      "0    [0.695589, 0.742796, 0.86392, 0.734774, 1.07, ...      0\n",
      "1    [0.742796, 0.86392, 0.734774, 1.07, 1.43, 1.33...      1\n",
      "2    [0.86392, 0.734774, 1.07, 1.43, 1.33, 1.4, 1.4...      1\n",
      "3    [0.734774, 1.07, 1.43, 1.33, 1.4, 1.4, 1.31, 2...      1\n",
      "4    [1.07, 1.43, 1.33, 1.4, 1.4, 1.31, 2.38, 3.18,...      1\n",
      "..                                                 ...    ...\n",
      "357  [3.28, 3.19, 3.19, 3.2, 2.98, 3.18, 3.12, 3.15...      1\n",
      "358  [3.19, 3.19, 3.2, 2.98, 3.18, 3.12, 3.15, 3.13...      1\n",
      "359  [3.19, 3.2, 2.98, 3.18, 3.12, 3.15, 3.13, 3.63...      1\n",
      "360  [3.2, 2.98, 3.18, 3.12, 3.15, 3.13, 3.63, 3.53...      0\n",
      "361  [2.98, 3.18, 3.12, 3.15, 3.13, 3.63, 3.53, 3.2...      1\n",
      "\n",
      "[362 rows x 2 columns]\n",
      "Missing values in aeternity dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in binance-coin dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in bitcoin dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in bitcoin-cash dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in bitcoin-gold dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in bytecoin-bcn dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in cardano dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in dash dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in decred dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in eos dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in ethereum dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in ethereum-classic dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in icon dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in iota dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in lisk dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in litecoin dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in monero dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in nem dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in neo dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in omisego dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in ontology dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in qtum dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in ripple dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in stellar dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in tether dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in tron dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in vechain dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in zcash dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in zilliqa dataset:\n",
      "close_values    0\n",
      "label           0\n",
      "dtype: int64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('crypto-markets.csv')\n",
    "\n",
    "# Filter data for cryptocurrencies with ranknow < 30\n",
    "filtered_data = data[data['ranknow'] < 30]\n",
    "\n",
    "# Convert the date column to datetime and set it as the index\n",
    "filtered_data.loc[:, 'date'] = pd.to_datetime(filtered_data['date'])\n",
    "filtered_data.set_index('date', inplace=True)\n",
    "\n",
    "# Initialize a dictionary to hold the separate datasets\n",
    "datasets_dict = {}\n",
    "\n",
    "# Group the filtered data by the 'slug' column\n",
    "grouped = filtered_data.groupby('slug')\n",
    "\n",
    "# Iterate over each group\n",
    "for crypto, group in grouped:\n",
    "    datasets_with_labels = []\n",
    "    close_values = group['close'].values\n",
    "\n",
    "    for start in range(len(close_values) - 9):\n",
    "        end = start + 10\n",
    "        window = close_values[start:end]\n",
    "        value_day_7 = window[6]\n",
    "        value_day_10 = window[9]\n",
    "        label = 1 if value_day_10 > value_day_7 else 0\n",
    "\n",
    "        datasets_with_labels.append((window, label))\n",
    "    \n",
    "    # Convert the list of tuples into a DataFrame\n",
    "    dataset = pd.DataFrame(datasets_with_labels, columns=['close_values', 'label'])\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    datasets_dict[crypto] = dataset\n",
    "\n",
    "# Now datasets_dict contains 30 DataFrames, one for each cryptocurrency\n",
    "# You can access each dataset like this: datasets_dict['bitcoin']\n",
    "\n",
    "# Print to check one of the datasets\n",
    "print(datasets_dict['aeternity'])\n",
    "\n",
    "# Print missing values for each dataset\n",
    "for crypto, df in datasets_dict.items():\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(f'Missing values in {crypto} dataset:\\n{missing_values}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution for aeternity:\n",
      "label\n",
      "0    186\n",
      "1    176\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for aeternity: 0.946236559139785\n",
      "\n",
      "Class distribution for binance-coin:\n",
      "label\n",
      "1    167\n",
      "0    141\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for binance-coin: 0.844311377245509\n",
      "\n",
      "Class distribution for bitcoin:\n",
      "label\n",
      "1    1039\n",
      "0     818\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for bitcoin: 0.7872954764196343\n",
      "\n",
      "Class distribution for bitcoin-cash:\n",
      "label\n",
      "0    163\n",
      "1    147\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for bitcoin-cash: 0.901840490797546\n",
      "\n",
      "Class distribution for bitcoin-gold:\n",
      "label\n",
      "0    126\n",
      "1     92\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for bitcoin-gold: 0.7301587301587301\n",
      "\n",
      "Class distribution for bytecoin-bcn:\n",
      "label\n",
      "0    827\n",
      "1    614\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for bytecoin-bcn: 0.7424425634824667\n",
      "\n",
      "Class distribution for cardano:\n",
      "label\n",
      "1    121\n",
      "0    119\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for cardano: 0.9834710743801653\n",
      "\n",
      "Class distribution for dash:\n",
      "label\n",
      "0    819\n",
      "1    746\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for dash: 0.9108669108669109\n",
      "\n",
      "Class distribution for decred:\n",
      "label\n",
      "0    436\n",
      "1    403\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for decred: 0.9243119266055045\n",
      "\n",
      "Class distribution for eos:\n",
      "label\n",
      "0    175\n",
      "1    157\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for eos: 0.8971428571428571\n",
      "\n",
      "Class distribution for ethereum:\n",
      "label\n",
      "1    538\n",
      "0    488\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for ethereum: 0.9070631970260223\n",
      "\n",
      "Class distribution for ethereum-classic:\n",
      "label\n",
      "0    351\n",
      "1    323\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for ethereum-classic: 0.9202279202279202\n",
      "\n",
      "Class distribution for icon:\n",
      "label\n",
      "1    107\n",
      "0    107\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for icon: 1.0\n",
      "\n",
      "Class distribution for iota:\n",
      "label\n",
      "0    181\n",
      "1    169\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for iota: 0.9337016574585635\n",
      "\n",
      "Class distribution for lisk:\n",
      "label\n",
      "0    409\n",
      "1    374\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for lisk: 0.9144254278728606\n",
      "\n",
      "Class distribution for litecoin:\n",
      "label\n",
      "0    991\n",
      "1    866\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for litecoin: 0.8738647830474269\n",
      "\n",
      "Class distribution for monero:\n",
      "label\n",
      "0    745\n",
      "1    723\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for monero: 0.9704697986577181\n",
      "\n",
      "Class distribution for nem:\n",
      "label\n",
      "1    591\n",
      "0    563\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for nem: 0.9526226734348562\n",
      "\n",
      "Class distribution for neo:\n",
      "label\n",
      "0    328\n",
      "1    299\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for neo: 0.9115853658536586\n",
      "\n",
      "Class distribution for omisego:\n",
      "label\n",
      "0    163\n",
      "1    156\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for omisego: 0.9570552147239264\n",
      "\n",
      "Class distribution for ontology:\n",
      "label\n",
      "1    50\n",
      "0    32\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for ontology: 0.64\n",
      "\n",
      "Class distribution for qtum:\n",
      "label\n",
      "0    186\n",
      "1    184\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for qtum: 0.989247311827957\n",
      "\n",
      "Class distribution for ripple:\n",
      "label\n",
      "0    963\n",
      "1    796\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for ripple: 0.8265835929387332\n",
      "\n",
      "Class distribution for stellar:\n",
      "label\n",
      "0    765\n",
      "1    628\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for stellar: 0.8209150326797385\n",
      "\n",
      "Class distribution for tether:\n",
      "label\n",
      "0    969\n",
      "1    215\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for tether: 0.2218782249742002\n",
      "\n",
      "Class distribution for tron:\n",
      "label\n",
      "0    134\n",
      "1    124\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for tron: 0.9253731343283582\n",
      "\n",
      "Class distribution for vechain:\n",
      "label\n",
      "1    142\n",
      "0    138\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for vechain: 0.971830985915493\n",
      "\n",
      "Class distribution for zcash:\n",
      "label\n",
      "0    325\n",
      "1    252\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for zcash: 0.7753846153846153\n",
      "\n",
      "Class distribution for zilliqa:\n",
      "label\n",
      "1    63\n",
      "0    61\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio for zilliqa: 0.9682539682539683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Function to check balance and plot distribution for each dataset\n",
    "def check_balance_and_plot(datasets_dict):\n",
    "    num_datasets = len(datasets_dict)\n",
    "    cols = 5  # Number of columns for subplots\n",
    "    rows = math.ceil(num_datasets / cols)  # Number of rows for subplots\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "    for idx, (crypto, df) in enumerate(datasets_dict.items()):\n",
    "        # Checking balance of the dataset\n",
    "        class_counts = df['label'].value_counts()\n",
    "        print(f'Class distribution for {crypto}:')\n",
    "        print(class_counts)\n",
    "\n",
    "        # Plotting the class distribution\n",
    "        class_counts.plot(kind='bar', ax=axes[idx])\n",
    "        axes[idx].set_title(f'Class Distribution for {crypto}')\n",
    "        axes[idx].set_xlabel('Class')\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "        # Calculating imbalance ratio\n",
    "        imbalance_ratio = class_counts.min() / class_counts.max()\n",
    "        print(f\"Imbalance Ratio for {crypto}: {imbalance_ratio}\\n\")\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for ax in axes[num_datasets:]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to check balance and plot for each dataset\n",
    "check_balance_and_plot(datasets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/um/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    "\n",
    "# Assuming datasets_dict is already created\n",
    "results = []\n",
    "\n",
    "classifiers = {\n",
    "    \"Multi-Layer Perceptron\": MLPClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Balanced Random Forest\": BalancedRandomForestClassifier(replacement=True, sampling_strategy='all', random_state=42, bootstrap=False),\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    \"Support Vector Machine\": SVC(probability=True),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "for crypto, df in datasets_dict.items():\n",
    "    X = np.array(df['close_values'].apply(lambda x: x[:7]).tolist())\n",
    "    y = df['label'].astype(int).values\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        metrics = {\n",
    "            'balanced_accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': [],\n",
    "            'roc_auc': [],\n",
    "            'log_loss': []\n",
    "        }\n",
    "        for train_index, test_index in rskf.split(X, y):\n",
    "            model = clf\n",
    "            model.fit(X[train_index], y[train_index])\n",
    "            y_pred = model.predict(X[test_index])\n",
    "            y_prob = model.predict_proba(X[test_index]) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "            metrics['balanced_accuracy'].append(balanced_accuracy_score(y[test_index], y_pred))\n",
    "            metrics['precision'].append(precision_score(y[test_index], y_pred))\n",
    "            metrics['recall'].append(recall_score(y[test_index], y_pred))\n",
    "            metrics['f1'].append(f1_score(y[test_index], y_pred))\n",
    "            if y_prob is not None:\n",
    "                metrics['roc_auc'].append(roc_auc_score(y[test_index], y_prob[:, 1]))\n",
    "                metrics['log_loss'].append(log_loss(y[test_index], y_prob))\n",
    "            else:\n",
    "                metrics['roc_auc'].append(np.nan)\n",
    "                metrics['log_loss'].append(np.nan)\n",
    "\n",
    "        mean_metrics = {metric: np.nanmean(values) for metric, values in metrics.items()}\n",
    "        std_balanced_accuracy = np.nanstd(metrics['balanced_accuracy'])\n",
    "\n",
    "        results.append({\n",
    "            'crypto': crypto,\n",
    "            'classifier': clf_name,\n",
    "            **mean_metrics,\n",
    "            'balanced_accuracy_std': std_balanced_accuracy\n",
    "        })\n",
    "\n",
    "# Konwersja wynikw do DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Pivot the DataFrame to get the desired format\n",
    "pivot_df = results_df.pivot_table(index='crypto', columns='classifier', values=[\n",
    "    'balanced_accuracy', 'balanced_accuracy_std',\n",
    "    'precision', 'recall', 'f1', 'roc_auc', 'log_loss'\n",
    "])\n",
    "\n",
    "# Flatten the multi-index columns\n",
    "pivot_df.columns = ['_'.join(col).strip() for col in pivot_df.columns.values]\n",
    "\n",
    "# Save the pivoted DataFrame to a CSV file\n",
    "pivot_df.to_csv('pivoted_classification_results.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Wczytanie danych z pliku CSV\n",
    "results_df = pd.read_csv('classification_results.csv')\n",
    "\n",
    "# Filtrowanie danych dla Bitcoina\n",
    "bitcoin_results = results_df[results_df['crypto'] == 'bitcoin']\n",
    "bitcoin_results = bitcoin_results[bitcoin_results['classifier'] == 'Decision Tree']\n",
    "\n",
    "# Wybr metryk do wywietlenia\n",
    "metrics = ['balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Przygotowanie danych do wykresu\n",
    "classifier_names = bitcoin_results['classifier']\n",
    "metric_values = bitcoin_results[metrics]\n",
    "\n",
    "# Utworzenie wykresu supkowego\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Tworzenie wykresu dla kadej metryki\n",
    "width = 0.15  # Szeroko supkw\n",
    "x = np.arange(len(classifier_names))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i * width, bitcoin_results[metric], width, label=metric)\n",
    "\n",
    "# Dodanie etykiet i tytuu\n",
    "ax.set_xlabel('Klasyfikator')\n",
    "ax.set_ylabel('Warto Metryki')\n",
    "ax.set_title('Wyniki klasyfikacji dla Bitcoina')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(classifier_names)\n",
    "ax.legend()\n",
    "\n",
    "# Obrcenie etykiet na osi X dla lepszej czytelnoci\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Wywietlenie wykresu\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"6249734976process_stream_events\"\n",
      "    while executing\n",
      "\"6249734976process_stream_events\"\n",
      "    (\"after\" script)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Wczytanie danych z pliku CSV\n",
    "results_df = pd.read_csv('classification_results.csv')\n",
    "\n",
    "# Filtrowanie danych dla Bitcoina\n",
    "bitcoin_results = results_df[results_df['crypto'] == 'bitcoin']\n",
    "bitcoin_results = bitcoin_results[bitcoin_results['classifier'] == 'Decision Tree']\n",
    "\n",
    "# Wybr metryk do wywietlenia\n",
    "metrics = ['log_loss']\n",
    "\n",
    "# Przygotowanie danych do wykresu\n",
    "classifier_names = bitcoin_results['classifier']\n",
    "metric_values = bitcoin_results[metrics]\n",
    "\n",
    "# Utworzenie wykresu supkowego\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Tworzenie wykresu dla kadej metryki\n",
    "width = 0.15  # Szeroko supkw\n",
    "x = np.arange(len(classifier_names))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i * width, bitcoin_results[metric], width, label=metric)\n",
    "\n",
    "# Dodanie etykiet i tytuu\n",
    "ax.set_xlabel('Klasyfikator')\n",
    "ax.set_ylabel('Warto Metryki')\n",
    "ax.set_title('Wyniki klasyfikacji dla Bitcoina')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(classifier_names)\n",
    "ax.legend()\n",
    "\n",
    "# Obrcenie etykiet na osi X dla lepszej czytelnoci\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Wywietlenie wykresu\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         crypto              classifier  balanced_accuracy  precision  \\\n",
      "0     aeternity  Multi-Layer Perceptron           0.537970   0.511628   \n",
      "1     aeternity  Multi-Layer Perceptron           0.589715   0.575000   \n",
      "2     aeternity  Multi-Layer Perceptron           0.542471   0.526316   \n",
      "3     aeternity  Multi-Layer Perceptron           0.558301   0.534884   \n",
      "4     aeternity  Multi-Layer Perceptron           0.583012   0.571429   \n",
      "...         ...                     ...                ...        ...   \n",
      "2025    zilliqa     K-Nearest Neighbors           0.717949   0.727273   \n",
      "2026    zilliqa     K-Nearest Neighbors           0.599359   0.615385   \n",
      "2027    zilliqa     K-Nearest Neighbors           0.644231   0.700000   \n",
      "2028    zilliqa     K-Nearest Neighbors           0.647436   0.750000   \n",
      "2029    zilliqa     K-Nearest Neighbors           0.541667   0.533333   \n",
      "\n",
      "        recall        f1   roc_auc  log_loss  \n",
      "0     0.628571  0.564103  0.524060  0.693111  \n",
      "1     0.638889  0.605263  0.586336  0.682202  \n",
      "2     0.571429  0.547945  0.588417  0.673225  \n",
      "3     0.657143  0.589744  0.527413  0.692446  \n",
      "4     0.571429  0.571429  0.598456  0.680859  \n",
      "...        ...       ...       ...       ...  \n",
      "2025  0.666667  0.695652  0.756410  0.559339  \n",
      "2026  0.615385  0.615385  0.689103  0.625847  \n",
      "2027  0.538462  0.608696  0.682692  3.374240  \n",
      "2028  0.461538  0.571429  0.820513  0.540087  \n",
      "2029  0.666667  0.592593  0.746528  0.595667  \n",
      "\n",
      "[2030 rows x 8 columns]\n",
      "Mean Performance Metrics (Loaded from CSV):\n",
      "Log_loss:\n",
      "   aeternity - Balanced Random Forest: Mean = 0.7293\n",
      "   aeternity - Decision Tree: Mean = 16.6325\n",
      "   aeternity - K-Nearest Neighbors: Mean = 2.2185\n",
      "   aeternity - Logistic Regression: Mean = 0.6870\n",
      "   aeternity - Multi-Layer Perceptron: Mean = 0.6849\n",
      "   aeternity - Random Forest: Mean = 0.7299\n",
      "   aeternity - Support Vector Machine: Mean = 0.6862\n",
      "   binance-coin - Balanced Random Forest: Mean = 0.5631\n",
      "   binance-coin - Decision Tree: Mean = 12.8126\n",
      "   binance-coin - K-Nearest Neighbors: Mean = 1.7969\n",
      "   binance-coin - Logistic Regression: Mean = 0.6884\n",
      "   binance-coin - Multi-Layer Perceptron: Mean = 0.6663\n",
      "   binance-coin - Random Forest: Mean = 0.5549\n",
      "   binance-coin - Support Vector Machine: Mean = 0.6675\n",
      "   bitcoin - Balanced Random Forest: Mean = 0.6509\n",
      "   bitcoin - Decision Tree: Mean = 15.0712\n",
      "   bitcoin - K-Nearest Neighbors: Mean = 1.8912\n",
      "   bitcoin - Logistic Regression: Mean = 0.6989\n",
      "   bitcoin - Multi-Layer Perceptron: Mean = 3.5726\n",
      "   bitcoin - Random Forest: Mean = 0.6611\n",
      "   bitcoin - Support Vector Machine: Mean = 0.6866\n",
      "   bitcoin-cash - Balanced Random Forest: Mean = 0.6393\n",
      "   bitcoin-cash - Decision Tree: Mean = 14.9407\n",
      "   bitcoin-cash - K-Nearest Neighbors: Mean = 1.7290\n",
      "   bitcoin-cash - Logistic Regression: Mean = 0.7016\n",
      "   bitcoin-cash - Multi-Layer Perceptron: Mean = 4.1299\n",
      "   bitcoin-cash - Random Forest: Mean = 0.6518\n",
      "   bitcoin-cash - Support Vector Machine: Mean = 0.6966\n",
      "   bitcoin-gold - Balanced Random Forest: Mean = 0.7262\n",
      "   bitcoin-gold - Decision Tree: Mean = 12.3981\n",
      "   bitcoin-gold - K-Nearest Neighbors: Mean = 2.4008\n",
      "   bitcoin-gold - Logistic Regression: Mean = 0.7353\n",
      "   bitcoin-gold - Multi-Layer Perceptron: Mean = 1.9858\n",
      "   bitcoin-gold - Random Forest: Mean = 0.7322\n",
      "   bitcoin-gold - Support Vector Machine: Mean = 0.6899\n",
      "   bytecoin-bcn - Balanced Random Forest: Mean = 0.6909\n",
      "   bytecoin-bcn - Decision Tree: Mean = 16.0838\n",
      "   bytecoin-bcn - K-Nearest Neighbors: Mean = 2.1821\n",
      "   bytecoin-bcn - Logistic Regression: Mean = 0.6931\n",
      "   bytecoin-bcn - Multi-Layer Perceptron: Mean = 0.6822\n",
      "   bytecoin-bcn - Random Forest: Mean = 0.6904\n",
      "   bytecoin-bcn - Support Vector Machine: Mean = 0.6787\n",
      "   cardano - Balanced Random Forest: Mean = 0.6635\n",
      "   cardano - Decision Tree: Mean = 13.2911\n",
      "   cardano - K-Nearest Neighbors: Mean = 1.6483\n",
      "   cardano - Logistic Regression: Mean = 0.6781\n",
      "   cardano - Multi-Layer Perceptron: Mean = 0.6790\n",
      "   cardano - Random Forest: Mean = 0.6548\n",
      "   cardano - Support Vector Machine: Mean = 0.6744\n",
      "   dash - Balanced Random Forest: Mean = 0.7255\n",
      "   dash - Decision Tree: Mean = 15.8799\n",
      "   dash - K-Nearest Neighbors: Mean = 1.9177\n",
      "   dash - Logistic Regression: Mean = 0.6963\n",
      "   dash - Multi-Layer Perceptron: Mean = 0.9320\n",
      "   dash - Random Forest: Mean = 0.7325\n",
      "   dash - Support Vector Machine: Mean = 0.6903\n",
      "   decred - Balanced Random Forest: Mean = 0.7317\n",
      "   decred - Decision Tree: Mean = 15.6161\n",
      "   decred - K-Nearest Neighbors: Mean = 1.9902\n",
      "   decred - Logistic Regression: Mean = 0.6940\n",
      "   decred - Multi-Layer Perceptron: Mean = 0.6998\n",
      "   decred - Random Forest: Mean = 0.7104\n",
      "   decred - Support Vector Machine: Mean = 0.6895\n",
      "   eos - Balanced Random Forest: Mean = 0.6411\n",
      "   eos - Decision Tree: Mean = 15.2513\n",
      "   eos - K-Nearest Neighbors: Mean = 1.7101\n",
      "   eos - Logistic Regression: Mean = 0.7032\n",
      "   eos - Multi-Layer Perceptron: Mean = 0.6976\n",
      "   eos - Random Forest: Mean = 0.6435\n",
      "   eos - Support Vector Machine: Mean = 0.7054\n",
      "   ethereum - Balanced Random Forest: Mean = 0.6625\n",
      "   ethereum - Decision Tree: Mean = 15.2109\n",
      "   ethereum - K-Nearest Neighbors: Mean = 1.6951\n",
      "   ethereum - Logistic Regression: Mean = 0.6997\n",
      "   ethereum - Multi-Layer Perceptron: Mean = 1.4037\n",
      "   ethereum - Random Forest: Mean = 0.6627\n",
      "   ethereum - Support Vector Machine: Mean = 0.6933\n",
      "   ethereum-classic - Balanced Random Forest: Mean = 0.6536\n",
      "   ethereum-classic - Decision Tree: Mean = 15.6960\n",
      "   ethereum-classic - K-Nearest Neighbors: Mean = 1.9352\n",
      "   ethereum-classic - Logistic Regression: Mean = 0.6935\n",
      "   ethereum-classic - Multi-Layer Perceptron: Mean = 0.6908\n",
      "   ethereum-classic - Random Forest: Mean = 0.6794\n",
      "   ethereum-classic - Support Vector Machine: Mean = 0.6918\n",
      "   icon - Balanced Random Forest: Mean = 0.7378\n",
      "   icon - Decision Tree: Mean = 15.0801\n",
      "   icon - K-Nearest Neighbors: Mean = 1.9317\n",
      "   icon - Logistic Regression: Mean = 0.7062\n",
      "   icon - Multi-Layer Perceptron: Mean = 0.7008\n",
      "   icon - Random Forest: Mean = 0.8111\n",
      "   icon - Support Vector Machine: Mean = 0.6671\n",
      "   iota - Balanced Random Forest: Mean = 0.6711\n",
      "   iota - Decision Tree: Mean = 15.0354\n",
      "   iota - K-Nearest Neighbors: Mean = 2.0546\n",
      "   iota - Logistic Regression: Mean = 0.6948\n",
      "   iota - Multi-Layer Perceptron: Mean = 0.6780\n",
      "   iota - Random Forest: Mean = 0.6747\n",
      "   iota - Support Vector Machine: Mean = 0.6903\n",
      "   lisk - Balanced Random Forest: Mean = 0.7088\n",
      "   lisk - Decision Tree: Mean = 15.7653\n",
      "   lisk - K-Nearest Neighbors: Mean = 1.9185\n",
      "   lisk - Logistic Regression: Mean = 0.6944\n",
      "   lisk - Multi-Layer Perceptron: Mean = 0.6893\n",
      "   lisk - Random Forest: Mean = 0.7100\n",
      "   lisk - Support Vector Machine: Mean = 0.6945\n",
      "   litecoin - Balanced Random Forest: Mean = 0.6767\n",
      "   litecoin - Decision Tree: Mean = 15.4405\n",
      "   litecoin - K-Nearest Neighbors: Mean = 2.0344\n",
      "   litecoin - Logistic Regression: Mean = 0.6936\n",
      "   litecoin - Multi-Layer Perceptron: Mean = 0.7210\n",
      "   litecoin - Random Forest: Mean = 0.6788\n",
      "   litecoin - Support Vector Machine: Mean = 0.6899\n",
      "   monero - Balanced Random Forest: Mean = 0.6851\n",
      "   monero - Decision Tree: Mean = 15.7870\n",
      "   monero - K-Nearest Neighbors: Mean = 1.9846\n",
      "   monero - Logistic Regression: Mean = 0.6959\n",
      "   monero - Multi-Layer Perceptron: Mean = 0.7649\n",
      "   monero - Random Forest: Mean = 0.6873\n",
      "   monero - Support Vector Machine: Mean = 0.6936\n",
      "   nem - Balanced Random Forest: Mean = 0.7371\n",
      "   nem - Decision Tree: Mean = 15.7580\n",
      "   nem - K-Nearest Neighbors: Mean = 1.6861\n",
      "   nem - Logistic Regression: Mean = 0.6900\n",
      "   nem - Multi-Layer Perceptron: Mean = 0.6907\n",
      "   nem - Random Forest: Mean = 0.7417\n",
      "   nem - Support Vector Machine: Mean = 0.6904\n",
      "   neo - Balanced Random Forest: Mean = 0.7560\n",
      "   neo - Decision Tree: Mean = 14.7992\n",
      "   neo - K-Nearest Neighbors: Mean = 1.8470\n",
      "   neo - Logistic Regression: Mean = 0.7044\n",
      "   neo - Multi-Layer Perceptron: Mean = 0.7260\n",
      "   neo - Random Forest: Mean = 0.7422\n",
      "   neo - Support Vector Machine: Mean = 0.6923\n",
      "   omisego - Balanced Random Forest: Mean = 0.6846\n",
      "   omisego - Decision Tree: Mean = 16.5584\n",
      "   omisego - K-Nearest Neighbors: Mean = 1.8255\n",
      "   omisego - Logistic Regression: Mean = 0.6791\n",
      "   omisego - Multi-Layer Perceptron: Mean = 0.6900\n",
      "   omisego - Random Forest: Mean = 0.7331\n",
      "   omisego - Support Vector Machine: Mean = 0.6935\n",
      "   ontology - Balanced Random Forest: Mean = 0.6531\n",
      "   ontology - Decision Tree: Mean = 15.1595\n",
      "   ontology - K-Nearest Neighbors: Mean = 1.7765\n",
      "   ontology - Logistic Regression: Mean = 0.7287\n",
      "   ontology - Multi-Layer Perceptron: Mean = 0.6755\n",
      "   ontology - Random Forest: Mean = 0.6352\n",
      "   ontology - Support Vector Machine: Mean = 0.6209\n",
      "   qtum - Balanced Random Forest: Mean = 0.6640\n",
      "   qtum - Decision Tree: Mean = 15.0507\n",
      "   qtum - K-Nearest Neighbors: Mean = 2.1654\n",
      "   qtum - Logistic Regression: Mean = 0.7134\n",
      "   qtum - Multi-Layer Perceptron: Mean = 0.7090\n",
      "   qtum - Random Forest: Mean = 0.6633\n",
      "   qtum - Support Vector Machine: Mean = 0.6820\n",
      "   ripple - Balanced Random Forest: Mean = 0.6713\n",
      "   ripple - Decision Tree: Mean = 15.6344\n",
      "   ripple - K-Nearest Neighbors: Mean = 2.1541\n",
      "   ripple - Logistic Regression: Mean = 0.6933\n",
      "   ripple - Multi-Layer Perceptron: Mean = 0.6895\n",
      "   ripple - Random Forest: Mean = 0.6693\n",
      "   ripple - Support Vector Machine: Mean = 0.6896\n",
      "   stellar - Balanced Random Forest: Mean = 0.6848\n",
      "   stellar - Decision Tree: Mean = 15.8739\n",
      "   stellar - K-Nearest Neighbors: Mean = 2.0543\n",
      "   stellar - Logistic Regression: Mean = 0.6938\n",
      "   stellar - Multi-Layer Perceptron: Mean = 0.6878\n",
      "   stellar - Random Forest: Mean = 0.6872\n",
      "   stellar - Support Vector Machine: Mean = 0.6877\n",
      "   tether - Balanced Random Forest: Mean = 0.3533\n",
      "   tether - Decision Tree: Mean = 5.6207\n",
      "   tether - K-Nearest Neighbors: Mean = 1.2334\n",
      "   tether - Logistic Regression: Mean = 0.6872\n",
      "   tether - Multi-Layer Perceptron: Mean = 0.4731\n",
      "   tether - Random Forest: Mean = 0.3539\n",
      "   tether - Support Vector Machine: Mean = 0.4207\n",
      "   tron - Balanced Random Forest: Mean = 0.6018\n",
      "   tron - Decision Tree: Mean = 13.4810\n",
      "   tron - K-Nearest Neighbors: Mean = 1.9375\n",
      "   tron - Logistic Regression: Mean = 0.6743\n",
      "   tron - Multi-Layer Perceptron: Mean = 0.6661\n",
      "   tron - Random Forest: Mean = 0.6591\n",
      "   tron - Support Vector Machine: Mean = 0.6429\n",
      "   vechain - Balanced Random Forest: Mean = 0.7063\n",
      "   vechain - Decision Tree: Mean = 14.0313\n",
      "   vechain - K-Nearest Neighbors: Mean = 1.3432\n",
      "   vechain - Logistic Regression: Mean = 0.6746\n",
      "   vechain - Multi-Layer Perceptron: Mean = 0.6489\n",
      "   vechain - Random Forest: Mean = 0.7060\n",
      "   vechain - Support Vector Machine: Mean = 0.6468\n",
      "   zcash - Balanced Random Forest: Mean = 0.6582\n",
      "   zcash - Decision Tree: Mean = 14.8952\n",
      "   zcash - K-Nearest Neighbors: Mean = 2.0662\n",
      "   zcash - Logistic Regression: Mean = 0.6941\n",
      "   zcash - Multi-Layer Perceptron: Mean = 1.0447\n",
      "   zcash - Random Forest: Mean = 0.6515\n",
      "   zcash - Support Vector Machine: Mean = 0.6749\n",
      "   zilliqa - Balanced Random Forest: Mean = 0.6283\n",
      "   zilliqa - Decision Tree: Mean = 14.3634\n",
      "   zilliqa - K-Nearest Neighbors: Mean = 1.5621\n",
      "   zilliqa - Logistic Regression: Mean = 0.6943\n",
      "   zilliqa - Multi-Layer Perceptron: Mean = 0.6967\n",
      "   zilliqa - Random Forest: Mean = 0.6208\n",
      "   zilliqa - Support Vector Machine: Mean = 0.6926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the results from the CSV file\n",
    "loaded_results_df = pd.read_csv('classification_results.csv')\n",
    "\n",
    "# Print the loaded results\n",
    "print(loaded_results_df)\n",
    "\n",
    "# Optionally, print the mean performance metrics again\n",
    "mean_loaded_results = loaded_results_df.groupby(['crypto', 'classifier'])[metrics].mean().reset_index()\n",
    "print(\"Mean Performance Metrics (Loaded from CSV):\")\n",
    "for metric in metrics:\n",
    "    print(f\"{metric.capitalize()}:\")\n",
    "    for _, row in mean_loaded_results.iterrows():\n",
    "        print(f\"   {row['crypto']} - {row['classifier']}: Mean = {row[metric]:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('classification_results.csv')\n",
    "\n",
    "# Filtrowanie danych dla Bitcoina\n",
    "bitcoin_results = results_df[results_df['crypto'] == 'bitcoin']\n",
    "\n",
    "# Wybr metryk do wywietlenia\n",
    "metrics = ['balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'log_loss']\n",
    "\n",
    "# Przygotowanie danych do wykresu\n",
    "classifier_names = bitcoin_results['classifier']\n",
    "metric_values = bitcoin_results[metrics]\n",
    "\n",
    "# Utworzenie wykresu supkowego\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Tworzenie wykresu dla kadej metryki\n",
    "width = 0.15  # Szeroko supkw\n",
    "x = np.arange(len(classifier_names))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i * width, bitcoin_results[metric], width, label=metric)\n",
    "\n",
    "# Dodanie etykiet i tytuu\n",
    "ax.set_xlabel('Klasyfikator')\n",
    "ax.set_ylabel('Warto Metryki')\n",
    "ax.set_title('Wyniki klasyfikacji dla Bitcoina')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(classifier_names)\n",
    "ax.legend()\n",
    "\n",
    "# Obrcenie etykiet na osi X dla lepszej czytelnoci\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Wywietlenie wykresu\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              crypto  balanced_accuracy_Balanced Random Forest  \\\n",
      "0          aeternity                                  0.544775   \n",
      "1       binance-coin                                  0.671891   \n",
      "2            bitcoin                                  0.628519   \n",
      "3       bitcoin-cash                                  0.635970   \n",
      "4       bitcoin-gold                                  0.643893   \n",
      "5       bytecoin-bcn                                  0.570540   \n",
      "6            cardano                                  0.649877   \n",
      "7               dash                                  0.596228   \n",
      "8             decred                                  0.568222   \n",
      "9                eos                                  0.634528   \n",
      "10          ethereum                                  0.625721   \n",
      "11  ethereum-classic                                  0.614757   \n",
      "12              icon                                  0.563745   \n",
      "13              iota                                  0.616622   \n",
      "14              lisk                                  0.576205   \n",
      "15          litecoin                                  0.590247   \n",
      "16            monero                                  0.601720   \n",
      "17               nem                                  0.587965   \n",
      "18               neo                                  0.627118   \n",
      "19           omisego                                  0.577769   \n",
      "20          ontology                                  0.634524   \n",
      "21              qtum                                  0.590659   \n",
      "22            ripple                                  0.599382   \n",
      "23           stellar                                  0.576945   \n",
      "24            tether                                  0.852056   \n",
      "25              tron                                  0.711839   \n",
      "26           vechain                                  0.665218   \n",
      "27             zcash                                  0.635667   \n",
      "28           zilliqa                                  0.638462   \n",
      "\n",
      "    balanced_accuracy_Decision Tree  balanced_accuracy_K-Nearest Neighbors  \\\n",
      "0                          0.529695                               0.593428   \n",
      "1                          0.643432                               0.658824   \n",
      "2                          0.579304                               0.603176   \n",
      "3                          0.595391                               0.600880   \n",
      "4                          0.647100                               0.652134   \n",
      "5                          0.546542                               0.568336   \n",
      "6                          0.576591                               0.619293   \n",
      "7                          0.546918                               0.606128   \n",
      "8                          0.557827                               0.576849   \n",
      "9                          0.572965                               0.620904   \n",
      "10                         0.577321                               0.604201   \n",
      "11                         0.567527                               0.613172   \n",
      "12                         0.568182                               0.621970   \n",
      "13                         0.576740                               0.586965   \n",
      "14                         0.557016                               0.590047   \n",
      "15                         0.572203                               0.581189   \n",
      "16                         0.546938                               0.616696   \n",
      "17                         0.552931                               0.599617   \n",
      "18                         0.596402                               0.625468   \n",
      "19                         0.540356                               0.583008   \n",
      "20                         0.590952                               0.654048   \n",
      "21                         0.572975                               0.596726   \n",
      "22                         0.556912                               0.587787   \n",
      "23                         0.555118                               0.580245   \n",
      "24                         0.738444                               0.705219   \n",
      "25                         0.632853                               0.659478   \n",
      "26                         0.592406                               0.675413   \n",
      "27                         0.581789                               0.614345   \n",
      "28                         0.631410                               0.643590   \n",
      "\n",
      "    balanced_accuracy_Logistic Regression  \\\n",
      "0                                0.560505   \n",
      "1                                0.574348   \n",
      "2                                0.491512   \n",
      "3                                0.534135   \n",
      "4                                0.395606   \n",
      "5                                0.500000   \n",
      "6                                0.595319   \n",
      "7                                0.498147   \n",
      "8                                0.530658   \n",
      "9                                0.478600   \n",
      "10                               0.504379   \n",
      "11                               0.539767   \n",
      "12                               0.544697   \n",
      "13                               0.531659   \n",
      "14                               0.534090   \n",
      "15                               0.500548   \n",
      "16                               0.493344   \n",
      "17                               0.532507   \n",
      "18                               0.509439   \n",
      "19                               0.534888   \n",
      "20                               0.545714   \n",
      "21                               0.544197   \n",
      "22                               0.504234   \n",
      "23                               0.499484   \n",
      "24                               0.615664   \n",
      "25                               0.607248   \n",
      "26                               0.588602   \n",
      "27                               0.525240   \n",
      "28                               0.484615   \n",
      "\n",
      "    balanced_accuracy_Multi-Layer Perceptron  balanced_accuracy_Random Forest  \\\n",
      "0                                   0.557114                         0.543984   \n",
      "1                                   0.582839                         0.697635   \n",
      "2                                   0.505630                         0.613169   \n",
      "3                                   0.495503                         0.630457   \n",
      "4                                   0.498314                         0.646919   \n",
      "5                                   0.500000                         0.577856   \n",
      "6                                   0.597569                         0.639703   \n",
      "7                                   0.507606                         0.604398   \n",
      "8                                   0.533825                         0.582977   \n",
      "9                                   0.510068                         0.644137   \n",
      "10                                  0.478718                         0.621675   \n",
      "11                                  0.543603                         0.621164   \n",
      "12                                  0.559199                         0.584740   \n",
      "13                                  0.552552                         0.609292   \n",
      "14                                  0.541297                         0.558293   \n",
      "15                                  0.509975                         0.602327   \n",
      "16                                  0.508695                         0.597149   \n",
      "17                                  0.528909                         0.591143   \n",
      "18                                  0.518318                         0.624036   \n",
      "19                                  0.556079                         0.590770   \n",
      "20                                  0.486190                         0.613095   \n",
      "21                                  0.537334                         0.593360   \n",
      "22                                  0.500882                         0.588894   \n",
      "23                                  0.500000                         0.577031   \n",
      "24                                  0.500000                         0.758975   \n",
      "25                                  0.562054                         0.713839   \n",
      "26                                  0.613170                         0.666881   \n",
      "27                                  0.507538                         0.625113   \n",
      "28                                  0.494551                         0.618590   \n",
      "\n",
      "    balanced_accuracy_Support Vector Machine  \\\n",
      "0                                   0.556182   \n",
      "1                                   0.596159   \n",
      "2                                   0.499236   \n",
      "3                                   0.543573   \n",
      "4                                   0.480456   \n",
      "5                                   0.524027   \n",
      "6                                   0.612507   \n",
      "7                                   0.523435   \n",
      "8                                   0.544682   \n",
      "9                                   0.509254   \n",
      "10                                  0.494657   \n",
      "11                                  0.547451   \n",
      "12                                  0.643398   \n",
      "13                                  0.560612   \n",
      "14                                  0.515504   \n",
      "15                                  0.511816   \n",
      "16                                  0.520778   \n",
      "17                                  0.524516   \n",
      "18                                  0.481682   \n",
      "19                                  0.545051   \n",
      "20                                  0.636667   \n",
      "21                                  0.568783   \n",
      "22                                  0.500894   \n",
      "23                                  0.511423   \n",
      "24                                  0.557761   \n",
      "25                                  0.638409   \n",
      "26                                  0.625185   \n",
      "27                                  0.569431   \n",
      "28                                  0.555769   \n",
      "\n",
      "    balanced_accuracy_std_Balanced Random Forest  \\\n",
      "0                                       0.044557   \n",
      "1                                       0.078026   \n",
      "2                                       0.020315   \n",
      "3                                       0.049651   \n",
      "4                                       0.048377   \n",
      "5                                       0.022961   \n",
      "6                                       0.053807   \n",
      "7                                       0.025350   \n",
      "8                                       0.030283   \n",
      "9                                       0.026182   \n",
      "10                                      0.027814   \n",
      "11                                      0.038684   \n",
      "12                                      0.053493   \n",
      "13                                      0.040198   \n",
      "14                                      0.020186   \n",
      "15                                      0.025799   \n",
      "16                                      0.028479   \n",
      "17                                      0.030853   \n",
      "18                                      0.050488   \n",
      "19                                      0.051770   \n",
      "20                                      0.115152   \n",
      "21                                      0.067120   \n",
      "22                                      0.023830   \n",
      "23                                      0.018478   \n",
      "24                                      0.023953   \n",
      "25                                      0.071434   \n",
      "26                                      0.065677   \n",
      "27                                      0.037910   \n",
      "28                                      0.055659   \n",
      "\n",
      "    balanced_accuracy_std_Decision Tree  \\\n",
      "0                              0.033638   \n",
      "1                              0.053622   \n",
      "2                              0.020412   \n",
      "3                              0.057574   \n",
      "4                              0.053582   \n",
      "5                              0.025430   \n",
      "6                              0.041951   \n",
      "7                              0.028523   \n",
      "8                              0.029034   \n",
      "9                              0.060055   \n",
      "10                             0.030063   \n",
      "11                             0.035871   \n",
      "12                             0.056578   \n",
      "13                             0.047683   \n",
      "14                             0.053961   \n",
      "15                             0.016838   \n",
      "16                             0.028566   \n",
      "17                             0.024480   \n",
      "18                             0.028963   \n",
      "19                             0.018516   \n",
      "20                             0.081551   \n",
      "21                             0.060200   \n",
      "22                             0.038116   \n",
      "23                             0.019199   \n",
      "24                             0.036559   \n",
      "25                             0.074577   \n",
      "26                             0.056963   \n",
      "27                             0.032920   \n",
      "28                             0.089411   \n",
      "\n",
      "    balanced_accuracy_std_K-Nearest Neighbors  \\\n",
      "0                                    0.043610   \n",
      "1                                    0.058876   \n",
      "2                                    0.010087   \n",
      "3                                    0.054467   \n",
      "4                                    0.030215   \n",
      "5                                    0.022366   \n",
      "6                                    0.056181   \n",
      "7                                    0.020549   \n",
      "8                                    0.032268   \n",
      "9                                    0.050305   \n",
      "10                                   0.028048   \n",
      "11                                   0.018584   \n",
      "12                                   0.052838   \n",
      "13                                   0.049334   \n",
      "14                                   0.034765   \n",
      "15                                   0.029574   \n",
      "16                                   0.032392   \n",
      "17                                   0.023007   \n",
      "18                                   0.048736   \n",
      "19                                   0.053182   \n",
      "20                                   0.059046   \n",
      "21                                   0.063664   \n",
      "22                                   0.021430   \n",
      "23                                   0.024362   \n",
      "24                                   0.036399   \n",
      "25                                   0.050736   \n",
      "26                                   0.052530   \n",
      "27                                   0.065172   \n",
      "28                                   0.085449   \n",
      "\n",
      "    balanced_accuracy_std_Logistic Regression  \\\n",
      "0                                    0.027079   \n",
      "1                                    0.031312   \n",
      "2                                    0.017997   \n",
      "3                                    0.054727   \n",
      "4                                    0.042359   \n",
      "5                                    0.000000   \n",
      "6                                    0.061293   \n",
      "7                                    0.018548   \n",
      "8                                    0.016143   \n",
      "9                                    0.043263   \n",
      "10                                   0.022753   \n",
      "11                                   0.023501   \n",
      "12                                   0.095792   \n",
      "13                                   0.032495   \n",
      "14                                   0.020118   \n",
      "15                                   0.011576   \n",
      "16                                   0.010443   \n",
      "17                                   0.025974   \n",
      "18                                   0.038363   \n",
      "19                                   0.047279   \n",
      "20                                   0.102225   \n",
      "21                                   0.039095   \n",
      "22                                   0.022818   \n",
      "23                                   0.023906   \n",
      "24                                   0.022268   \n",
      "25                                   0.031821   \n",
      "26                                   0.062037   \n",
      "27                                   0.047736   \n",
      "28                                   0.075844   \n",
      "\n",
      "    balanced_accuracy_std_Multi-Layer Perceptron  \\\n",
      "0                                       0.036103   \n",
      "1                                       0.062378   \n",
      "2                                       0.013658   \n",
      "3                                       0.042445   \n",
      "4                                       0.062167   \n",
      "5                                       0.000000   \n",
      "6                                       0.063083   \n",
      "7                                       0.021381   \n",
      "8                                       0.031629   \n",
      "9                                       0.038563   \n",
      "10                                      0.022412   \n",
      "11                                      0.036640   \n",
      "12                                      0.078868   \n",
      "13                                      0.045130   \n",
      "14                                      0.038098   \n",
      "15                                      0.011019   \n",
      "16                                      0.018277   \n",
      "17                                      0.020297   \n",
      "18                                      0.050753   \n",
      "19                                      0.076135   \n",
      "20                                      0.097420   \n",
      "21                                      0.028241   \n",
      "22                                      0.003612   \n",
      "23                                      0.000000   \n",
      "24                                      0.000000   \n",
      "25                                      0.060643   \n",
      "26                                      0.064869   \n",
      "27                                      0.023272   \n",
      "28                                      0.083371   \n",
      "\n",
      "    balanced_accuracy_std_Random Forest  \\\n",
      "0                              0.061606   \n",
      "1                              0.067958   \n",
      "2                              0.023997   \n",
      "3                              0.041359   \n",
      "4                              0.035078   \n",
      "5                              0.016254   \n",
      "6                              0.065979   \n",
      "7                              0.024848   \n",
      "8                              0.034271   \n",
      "9                              0.025668   \n",
      "10                             0.026624   \n",
      "11                             0.026112   \n",
      "12                             0.048653   \n",
      "13                             0.037639   \n",
      "14                             0.025362   \n",
      "15                             0.024312   \n",
      "16                             0.030341   \n",
      "17                             0.032485   \n",
      "18                             0.046940   \n",
      "19                             0.050448   \n",
      "20                             0.080371   \n",
      "21                             0.046989   \n",
      "22                             0.021321   \n",
      "23                             0.020775   \n",
      "24                             0.034038   \n",
      "25                             0.064549   \n",
      "26                             0.067762   \n",
      "27                             0.041481   \n",
      "28                             0.075453   \n",
      "\n",
      "    balanced_accuracy_std_Support Vector Machine  \n",
      "0                                       0.041618  \n",
      "1                                       0.039698  \n",
      "2                                       0.006832  \n",
      "3                                       0.059554  \n",
      "4                                       0.051553  \n",
      "5                                       0.021324  \n",
      "6                                       0.070464  \n",
      "7                                       0.021489  \n",
      "8                                       0.022062  \n",
      "9                                       0.048909  \n",
      "10                                      0.014850  \n",
      "11                                      0.041688  \n",
      "12                                      0.081045  \n",
      "13                                      0.051225  \n",
      "14                                      0.015817  \n",
      "15                                      0.016177  \n",
      "16                                      0.020505  \n",
      "17                                      0.022260  \n",
      "18                                      0.029352  \n",
      "19                                      0.053524  \n",
      "20                                      0.090477  \n",
      "21                                      0.026925  \n",
      "22                                      0.007171  \n",
      "23                                      0.012477  \n",
      "24                                      0.017463  \n",
      "25                                      0.033265  \n",
      "26                                      0.033788  \n",
      "27                                      0.028308  \n",
      "28                                      0.074580  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Wczytaj dane z pliku CSV\n",
    "# file_path = 'path_to_your_file.csv'\n",
    "data = pd.read_csv('pivoted_classification_results.csv')\n",
    "\n",
    "# Przefiltruj kolumny tylko dla `balanced_accuracy`\n",
    "balanced_acc_cols = [col for col in data.columns if 'balanced_accuracy' in col]\n",
    "data_bal_acc = data[['crypto'] + balanced_acc_cols]\n",
    "\n",
    "# Skrcone nazwy kolumn\n",
    "short_col_names = {\n",
    "    'balanced_accuracy_Balanced Random Forest': 'BRF',\n",
    "    'balanced_accuracy_Decision Tree': 'DT',\n",
    "    'balanced_accuracy_K-Nearest Neighbors': 'KNN',\n",
    "    'balanced_accuracy_Logistic Regression': 'LR',\n",
    "    'balanced_accuracy_Multi-Layer Perceptron': 'MLP',\n",
    "    'balanced_accuracy_Random Forest': 'RF',\n",
    "    'balanced_accuracy_Support Vector Machine': 'SVM'\n",
    "}\n",
    "print(data_bal_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         crypto Classifier 1 Classifier 2  t-statistic       p-value\n",
      "0     aeternity          BRF          BRF     0.000000           NaN\n",
      "1     aeternity          BRF           DT     5.132105  4.651283e-06\n",
      "2     aeternity          BRF          KNN   -14.826851  2.797731e-01\n",
      "3     aeternity          BRF           LR    -5.732062  6.933376e-08\n",
      "4     aeternity          BRF          MLP    -4.087927  3.044621e-04\n",
      "...         ...          ...          ...          ...           ...\n",
      "1416    zilliqa          SVM          KNN   -11.739675  1.626577e-02\n",
      "1417    zilliqa          SVM           LR    -1.654362  1.011430e-01\n",
      "1418    zilliqa          SVM          MLP    -0.321350  7.526688e-01\n",
      "1419    zilliqa          SVM           RF     3.117379  2.464814e-03\n",
      "1420    zilliqa          SVM          SVM     0.000000           NaN\n",
      "\n",
      "[1421 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Przefiltruj kolumny tylko dla `balanced_accuracy`\n",
    "from scipy.stats import t\n",
    "balanced_acc_cols = [col for col in data.columns if 'balanced_accuracy' in col]\n",
    "data_bal_acc = data[['crypto'] + balanced_acc_cols]\n",
    "\n",
    "# Skrcone nazwy kolumn\n",
    "short_col_names = {\n",
    "    'balanced_accuracy_Balanced Random Forest': 'BRF',\n",
    "    'balanced_accuracy_Decision Tree': 'DT',\n",
    "    'balanced_accuracy_K-Nearest Neighbors': 'KNN',\n",
    "    'balanced_accuracy_Logistic Regression': 'LR',\n",
    "    'balanced_accuracy_Multi-Layer Perceptron': 'MLP',\n",
    "    'balanced_accuracy_Random Forest': 'RF',\n",
    "    'balanced_accuracy_Support Vector Machine': 'SVM',\n",
    "    'balanced_accuracy_std_Balanced Random Forest': 'BRF_std',\n",
    "    'balanced_accuracy_std_Decision Tree': 'DT_std',\n",
    "    'balanced_accuracy_std_K-Nearest Neighbors': 'KNN_std',\n",
    "    'balanced_accuracy_std_Logistic Regression': 'LR_std',\n",
    "    'balanced_accuracy_std_Multi-Layer Perceptron': 'MLP_std',\n",
    "    'balanced_accuracy_std_Random Forest': 'RF_std',\n",
    "    'balanced_accuracy_std_Support Vector Machine': 'SVM_std'\n",
    "}\n",
    "\n",
    "# Zamie nazwy kolumn na skrcone\n",
    "data_bal_acc = data_bal_acc.rename(columns=short_col_names)\n",
    "\n",
    "# Wybierz dane dla pierwszej kryptowaluty (aeternity)\n",
    "crypto_data = data_bal_acc #[data_bal_acc['crypto'] == 'aeternity']\n",
    "\n",
    "# Lista klasyfikatorw\n",
    "classifiers = ['BRF', 'DT', 'KNN', 'LR', 'MLP', 'RF', 'SVM']\n",
    "\n",
    "# Oblicz test t-studenta dla kadej pary klasyfikatorw\n",
    "results = []\n",
    "\n",
    "cryptocurrencies = data_bal_acc['crypto'].unique()\n",
    "\n",
    "for crypto in cryptocurrencies: \n",
    "    for i in range(len(classifiers)):\n",
    "        for j in range(len(classifiers)):\n",
    "            clf1 = classifiers[i]\n",
    "            clf2 = classifiers[j]\n",
    "            \n",
    "            mean1 = crypto_data[f'{clf1}'].values[0]\n",
    "            mean2 = crypto_data[f'{clf2}'].values[0]\n",
    "            \n",
    "            std1 = crypto_data[f'{clf1}_std'].values[0]\n",
    "            std2 = crypto_data[f'{clf2}_std'].values[0]\n",
    "            \n",
    "            n1 = n2 = 361  # Zakadam, e mamy 30 prbek dla kadej metryki\n",
    "\n",
    "            # Oblicz statystyk t\n",
    "            t_stat = (mean1 - mean2) / np.sqrt((std1**2 / n1) + (std2**2 / n2))\n",
    "            \n",
    "            # Oblicz stopnie swobody\n",
    "            df = ((std1**2 / n1) - (std2**2 / n2))**2 / (((std1**2 / n1)**2 / (n1 - 1)) + ((std2**2 / n2)**2 / (n2 - 1)))\n",
    "            \n",
    "            # Oblicz p-value\n",
    "            p_value = 2 * (1 - t.cdf(np.abs(t_stat), df))\n",
    "            \n",
    "            # Dodaj wynik do listy tylko jeli p-value > 0.05\n",
    "            results.append({\n",
    "                'crypto': crypto,\n",
    "                'Classifier 1': clf1,\n",
    "                'Classifier 2': clf2,\n",
    "                't-statistic': t_stat,\n",
    "                'p-value': p_value\n",
    "            })\n",
    "            \n",
    "                \n",
    "            # n1 = n2 = 30  # Zakadam, e mamy 30 prbek dla kadej metryki\n",
    "\n",
    "            # # Oblicz statystyk t\n",
    "            # t_stat = (mean1 - mean2) / np.sqrt((std1**2 / n1) + (std2**2 / n2))\n",
    "            \n",
    "            # # Dodaj wynik do listy\n",
    "            # if t_stat > 2:\n",
    "            #     results.append({\n",
    "            #         'crypto': crypto,\n",
    "            #         'Classifier 1': clf1,\n",
    "            #         'Classifier 2': clf2,\n",
    "            #         't-statistic': t_stat\n",
    "            #     })\n",
    "\n",
    "\n",
    "# Konwertuj wyniki do DataFrame i wywietl\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('t_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/your/t_test_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load your CSV file\u001b[39;00m\n\u001b[1;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath/to/your/t_test_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Extract unique classifiers\u001b[39;00m\n\u001b[1;32m      8\u001b[0m classifiers_1 \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/um/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/um/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/envs/um/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/um/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/um/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/your/t_test_results.csv'"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load your CSV file\n",
    "# file_path = 'path/to/your/t_test_results.csv'\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# # Extract unique classifiers\n",
    "# classifiers_1 = data['classifier1'].unique()\n",
    "# classifiers_2 = data['classifier2'].unique()\n",
    "\n",
    "# # Split data into three groups\n",
    "# cryptos = data['cryptocurrency'].unique()\n",
    "# cryptos_split = [cryptos[i:i + 9] for i in range(0, len(cryptos), 9)]\n",
    "\n",
    "# # Function to generate LaTeX table for a group of cryptocurrencies\n",
    "# def generate_latex_table(group, classifiers_1, classifiers_2):\n",
    "#     latex = \"\\\\begin{table}[H]\\n\\\\centering\\n\\\\begin{tabular}{|\" + \"c|\" * (len(classifiers_2) + 1) + \"}\\n\"\n",
    "#     latex += \"\\\\hline\\n\"\n",
    "#     latex += \" & \" + \" & \".join(classifiers_2) + \" \\\\\\\\\\n\\\\hline\\n\"\n",
    "#     for crypto in group:\n",
    "#         for c1 in classifiers_1:\n",
    "#             row = [crypto + \" \" + c1] + ['' for _ in classifiers_2]\n",
    "#             for c2 in classifiers_2:\n",
    "#                 p_value = data[(data['cryptocurrency'] == crypto) & \n",
    "#                                (data['classifier1'] == c1) & \n",
    "#                                (data['classifier2'] == c2)]['p_value'].values[0]\n",
    "#                 color = \"white\" if p_value < 0.05 else \"black\"\n",
    "#                 cell_color = \"\\\\cellcolor{\" + color + \"}\"\n",
    "#                 row[classifiers_2.tolist().index(c2) + 1] = cell_color\n",
    "#             latex += \" & \".join(row) + \" \\\\\\\\\\n\\\\hline\\n\"\n",
    "#     latex += \"\\\\end{tabular}\\n\\\\end{table}\\n\"\n",
    "#     return latex\n",
    "\n",
    "# # Generate LaTeX code for each table\n",
    "# latex_code = \"\"\n",
    "# for i, group in enumerate(cryptos_split):\n",
    "#     latex_code += generate_latex_table(group, classifiers_1, classifiers_2) + \"\\n\"\n",
    "\n",
    "# # Print the LaTeX code\n",
    "# print(latex_code)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
